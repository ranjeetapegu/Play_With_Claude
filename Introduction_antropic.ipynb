{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48fc16f3",
   "metadata": {},
   "source": [
    "### Load the environment variables and create your API client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36be877c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "from anthropic import Anthropic \n",
    "\n",
    "client = Anthropic()\n",
    "model = \"claude-sonnet-4-0\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c530e239",
   "metadata": {},
   "source": [
    "## The Create Function "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfe993f",
   "metadata": {},
   "source": [
    "The Model , the name of claude model you want to use, max_token- a saftety limit on the response, messages - the conversional history you are sending to claude.\n",
    "\n",
    "2 types of messages -:\n",
    "* user messages- content we want to feed into the model \n",
    "* Assistant messages: - Content the model has produced "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "880586a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "message= client.messages.create(\n",
    "    model=model,\n",
    "    max_tokens = 500,\n",
    "    messages = #list of messages\n",
    "       [ {\"role\":\"user\",\n",
    "         \"content\": \"what is claude-sonnet? Answer in 2 -lines max\"\n",
    "         }\n",
    "    ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55e026b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Claude Sonnet (specifically Claude 3.5 Sonnet) is Anthropic's most advanced AI assistant model, known for strong reasoning, coding, and creative capabilities. It balances high performance with speed, making it suitable for complex tasks while maintaining efficient response times.\n"
     ]
    }
   ],
   "source": [
    "#print(message)\n",
    "print(message.content[0].text)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fabb9a98",
   "metadata": {},
   "source": [
    "## Multi-Turn Conversations \n",
    "\n",
    "Anthroic API/LLM doesn not store any message | --- >   For conversation  \n",
    "* 1. Manually maintain a list of messages in your code\n",
    "* 2. Provide that list of messages with each follow up request\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c09fe889",
   "metadata": {},
   "outputs": [],
   "source": [
    "##helper functions \n",
    "#userr messages\n",
    "\n",
    "def add_user_message(messages,text):\n",
    "    user_message= {\n",
    "        \"role\":\"user\",\n",
    "        \"content\":text  }\n",
    "    messages.append(user_message)\n",
    "\n",
    "## assistant function\n",
    "def add_assistant_message(messages,text):\n",
    "    assistant_message= {\n",
    "        \"role\":\"assistant\",\n",
    "        \"content\":text  }\n",
    "    messages.append(assistant_message)\n",
    "\n",
    "\n",
    "def chat(messages):\n",
    "    messages = client.messages.create(\n",
    "        model = model,\n",
    "        max_tokens = 1000,\n",
    "        messages = messages,\n",
    "        )\n",
    "    return messages.content[0].text\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb33b1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In action \n",
    "\n",
    "# make a starting list of messages\n",
    "messages = []\n",
    "# add the initial user message\n",
    "add_user_message(messages, \"what are different anthropic model, answer in 1-2 sentences\")\n",
    "\n",
    "answer =chat(messages)\n",
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3db366e",
   "metadata": {},
   "source": [
    "## add the assiustance messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fff507c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'what are different anthropic model, answer in 1-2 sentences'},\n",
       " {'role': 'assistant',\n",
       "  'content': 'Anthropic offers several Claude models including Claude 3.5 Sonnet (the most advanced), Claude 3 Opus (powerful for complex tasks), Claude 3 Haiku (fast and cost-effective), and Claude 2.1 (previous generation). These models vary in capabilities, speed, and pricing to suit different use cases from simple tasks to complex reasoning.'}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_assistant_message(messages, answer)\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92bb2919",
   "metadata": {},
   "source": [
    "# final user messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36f076e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'role': 'user', 'content': 'what are different anthropic model, answer in 1-2 sentences'}, {'role': 'assistant', 'content': 'Anthropic offers several Claude models including Claude 3.5 Sonnet (the most advanced), Claude 3 Opus (powerful for complex tasks), Claude 3 Haiku (fast and cost-effective), and Claude 2.1 (previous generation). These models vary in capabilities, speed, and pricing to suit different use cases from simple tasks to complex reasoning.'}, {'role': 'user', 'content': 'which is most costly one and when to use which model?'}]\n",
      "Claude 3 Opus is the most expensive model, designed for highly complex tasks requiring maximum intelligence like advanced research, complex analysis, and sophisticated reasoning. Use Claude 3.5 Sonnet for most general tasks requiring high performance, Claude 3 Haiku for simple, fast tasks where cost-efficiency matters, and Claude 2.1 for basic applications where the latest capabilities aren't necessary.\n"
     ]
    }
   ],
   "source": [
    "add_user_message(messages, \"which is most costly one and when to use which model?\")\n",
    "print(messages)\n",
    "\n",
    "answer = chat(messages)\n",
    "print(answer)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
